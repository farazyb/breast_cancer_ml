{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb33fb21",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "In this phase, we focus on acquiring the data, understanding its structure, and verifying its quality. This foundation is crucial before we move on to preprocessing or modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed58bde",
   "metadata": {},
   "source": [
    "## Collecting Initial Data\n",
    "- The dataset used in this project originates from the University of Wisconsin Hospitals, Madison. It was created by Dr. William H. Wolberg, W. Nick Street, and Olvi L. Mangasarian.\n",
    "- Dataset Specifics:\n",
    "    - Format: CSV (Comma Separated Values)\n",
    "    - File Name: dataset.csv\n",
    "    - Target Variable: Diagnosis (Benign vs. Malignant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f837ca",
   "metadata": {},
   "source": [
    "## Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f643d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.dataset import load, download_dataset2\n",
    "URL=\"https://drive.google.com/file/d/1MaNL7FS7rpX4GLxgGnXX0iD72kb1PR61/view?usp=sharing\"\n",
    "download_dataset2(URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee4a30",
   "metadata": {},
   "source": [
    "## Loading and have an overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4470c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from breast_cancer/data/raw/\n",
    "df = load()\n",
    "# show for sample from the Head \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c64f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load some sample from the end of data set\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538aac7",
   "metadata": {},
   "source": [
    "## Describing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5e68f",
   "metadata": {},
   "source": [
    "This section examines the structure, data types, and basic statistics of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d67a412",
   "metadata": {},
   "source": [
    "- Impoerting necessary library for understanding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac5f7e",
   "metadata": {},
   "source": [
    "* config out notebook for good visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfd8e52",
   "metadata": {},
   "source": [
    "### Dataset Shape and Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee07c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Number of samples: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294454f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c07cd71",
   "metadata": {},
   "source": [
    "Findings:\n",
    "- Every column shows “569 non-null”:\n",
    "    - That means 0 missing values in all 32 columns.\n",
    "    - So I don’t need dropna() or imputation.\n",
    "- Data types:\n",
    "    - I have three dtype groups:\n",
    "        - float64(30) → numeric features\n",
    "            - 30 columns are continuous numeric measurements (radius, texture, area, etc.).\n",
    "        - int64(1) → target\n",
    "            - 0/1 (benign vs malignant).\n",
    "- Memory:\n",
    "    - The whole dataset uses ~138 KB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36425c2",
   "metadata": {},
   "source": [
    "### Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbcbc7b",
   "metadata": {},
   "source": [
    "### Result\n",
    "- For each column:\n",
    "  - count: number of non-missing rows (all are 569 → no missing)\n",
    "  - mean: average value\n",
    "  - std: spread (standard deviation)\n",
    "  - min / max: smallest / largest\n",
    "  - 25% / 50% / 75%: quartiles (median is 50%)\n",
    "\n",
    "- Describing 31 feature is kind of hard. but by looking very fastly, we can understand that the scale of the data are not same, which means if we use data whitout standardizing them can make some problem in our predections.\n",
    "    - Examples of scale mismatch\n",
    "        - mean area:\n",
    "            mean ≈ 654.9, max ≈ 2501\n",
    "        - mean smoothness:\n",
    "            mean ≈ 0.096, max ≈ 0.163\n",
    "        - perimeter error:\n",
    "            mean ≈ 2.87, max ≈ 21.98\n",
    "        - area error:\n",
    "            mean ≈ 40.3, max ≈ 542.2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a8aa23",
   "metadata": {},
   "source": [
    "## Exploring Data \n",
    "In this section, we explore the data to understand relationships and distributions. We will start by looking at how features relate to each other to identify redundancy, and then dive into specific feature-target relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08642e3b",
   "metadata": {},
   "source": [
    "### Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858662dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create readable labels\n",
    "df['diagnosis_label'] = df['target'].map({0: 'Malignant', 1: 'Benign'})\n",
    "\n",
    "# Plot class distribution\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.countplot(data=df, x='diagnosis_label', hue='diagnosis_label', palette='viridis', legend=False, ax=ax)\n",
    "ax.set_title('Class Distribution')\n",
    "ax.set_xlabel('Diagnosis')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "# Add counts and percentages\n",
    "counts = df['diagnosis_label'].value_counts()\n",
    "pct = df['diagnosis_label'].value_counts(normalize=True) * 100\n",
    "text = f\"Malignant: {counts['Malignant']} ({pct['Malignant']:.1f}%)\\nBenign: {counts['Benign']} ({pct['Benign']:.1f}%)\"\n",
    "ax.text(0.4, 0.95, text, transform=ax.transAxes, va='top', ha='right', fontsize=10,\n",
    "        bbox=dict(facecolor='white', edgecolor='gray'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e55ad3",
   "metadata": {},
   "source": [
    "The dataset has class imbalance: 37.3% Malignant (212 samples) vs 62.7% Benign (357 samples). Stratified sampling should be used during train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f11a98",
   "metadata": {},
   "source": [
    "### Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50d4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.drop(['diagnosis_label', 'target'], axis=1)\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "# Clustered (sorted) correlation heatmap\n",
    "sns.clustermap(\n",
    "    corr_matrix,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    linewidths=0.5,\n",
    "    figsize=(18, 18)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9aabfc",
   "metadata": {},
   "source": [
    "Observation:\n",
    "The correlation heatmap shows two dominant redundant clusters and a set of independent features that add genuinely new information.\n",
    "1. Shape irregularity cluster\n",
    "    - Top-left block:\n",
    "        * mean concavity, mean concave points, worst concave points, mean compactness, worst compactness, worst concavity\n",
    "        * These are strongly positively correlated with each other (deep red). They measure related “boundary irregularity”.\n",
    "2. Size cluster\n",
    "    - Large central red block:\n",
    "        * mean radius, mean perimeter, mean area, plus their worst radius, worst perimeter, worst area\n",
    "        * These are almost the same information (very high correlations). This is the classic multicollinearity “size” group.\n",
    "3. Size error cluster\n",
    "    - Small red block near the size group:\n",
    "        * area error, radius error, perimeter error\n",
    "        * These errors correlate strongly with each other, and moderately with size (bigger tumors tend to have bigger measurement errors).\n",
    "4. Texture subcluster\n",
    "    - A tight 2×2 red block:\n",
    "        * mean texture ↔ worst texture\n",
    "        * Very strong mutual correlation, but comparatively weaker ties to the size/shape blocks.\n",
    "5. Smoothness / symmetry / fractal dimension group\n",
    "    - Mid-lower area shows moderate correlations among:\n",
    "        * mean smoothness, worst smoothness, mean symmetry, worst symmetry, worst fractal dimension \n",
    "        * They form a looser cluster (not as redundant as size).    \n",
    "6. Concavity/compactness error cluster\n",
    "    - Bottom-right strong block:\n",
    "        * concave points error, compactness error, concavity error\n",
    "        * These error-features move together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b8bde",
   "metadata": {},
   "source": [
    "### Feature Correlation with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc71d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df.select_dtypes(include=\"number\").columns.drop(\"target\")\n",
    "# Correlation with target\n",
    "corr_target = df[feature_cols].corrwith(df['target']).sort_values(key=lambda x: abs(x), ascending=False)\n",
    "# Plot top 10\n",
    "plt.figure(figsize=(10, 5))\n",
    "corr_target.head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Features by Correlation with Target')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Correlation')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26782cee",
   "metadata": {},
   "source": [
    "Observation:\n",
    "- The top 10 features most correlated with the target are all negatively correlated, meaning higher values of these features are associated with malignant tumors (target=0).\n",
    "- The strongest correlations come from two groups:\n",
    "  - Concavity/shape features: worst concave points,mean concave points, worst concavity, mean concavity — irregular, indented cell boundaries are strong indicators of malignancy.\n",
    "  - Size features: worst perimeter, worst radius, worst area, mean perimeter, mean radius, mean area — larger tumors tend to be malignant.\n",
    "- The \"worst\" (largest/most extreme) measurements generally correlate more strongly than the \"mean\" measurements, suggesting that the most extreme cells in a sample are more diagnostically informative.\n",
    "- This aligns with the earlier feature-feature correlation heatmap, where these same features formed dominant clusters (size cluster and shape irregularity cluster).\n",
    "- These top correlated features will be strong candidates for feature selection in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d085e",
   "metadata": {},
   "source": [
    "### Feature Distributions by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "# Select top 10 features by correlation\n",
    "top_features = corr_target.head(10).index.tolist()\n",
    "top_features.append(\"texture error\")\n",
    "top_features.append(\"symmetry error\")\n",
    "n = len(top_features)\n",
    "print(n)\n",
    "cols = 2\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "# Plot distributions\n",
    "fig = plt.figure(figsize=(16, 5 * rows))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "\n",
    "for i, feature in enumerate(top_features):\n",
    "    # Create a 2-row sub-grid per feature: boxplot (1/4 height) + histogram (3/4 height)\n",
    "    gs = gridspec.GridSpecFromSubplotSpec(\n",
    "        2, 1, subplot_spec=fig.add_gridspec(rows, cols)[i // cols, i % cols],\n",
    "        height_ratios=[1, 3], hspace=0.05\n",
    "    )\n",
    "\n",
    "    ax_box = fig.add_subplot(gs[0])\n",
    "    ax_hist = fig.add_subplot(gs[1], sharex=ax_box)\n",
    "\n",
    "    # Boxplot on top\n",
    "    sns.boxplot(data=df, x=feature, hue='diagnosis_label', ax=ax_box, palette='viridis', legend=False)\n",
    "    ax_box.set(xlabel='', ylabel='')\n",
    "    ax_box.tick_params(labelbottom=False)\n",
    "    ax_box.set_title(f'Distribution: {feature}')\n",
    "\n",
    "    # Histogram + KDE below\n",
    "    sns.histplot(data=df, x=feature, hue='diagnosis_label', kde=True, element='step', ax=ax_hist, palette='viridis')\n",
    "    ax_hist.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77df2e",
   "metadata": {},
   "source": [
    "### Observation: Combined Distribution & Boxplot Analysis (Top 10 Features)\n",
    "\n",
    "The combined histogram + boxplot visualization for the top 10 features most correlated with the target reveals:\n",
    "\n",
    "1. Clear Class Separation (Strong Predictors)\n",
    "   - worst concave points, mean concave points, worst perimeter, worst radius, worst area: The Malignant and Benign distributions are visibly shifted apart with minimal overlap. The boxplots confirm non-overlapping IQRs, making these the most discriminative features.\n",
    "\n",
    "2. Moderate Separation\n",
    "   - mean perimeter, mean radius, mean area, mean concavity, worst concavity: Distributions overlap partially, but the medians (visible in boxplots) are clearly displaced. These features still carry useful predictive signal.\n",
    "\n",
    "3. Skewness & Outliers\n",
    "   - The boxplots expose right-skewed distributions in area-based features (mean area, worst area), with several high-value outliers in the Malignant class. This suggests that extreme tumor sizes are strongly indicative of malignancy.\n",
    "\n",
    "4. Distribution Shape\n",
    "   - Malignant cases tend to have wider, flatter distributions (higher variance), while Benign cases are more tightly concentrated around lower values. This pattern is consistent across nearly all top features.\n",
    "5. I intentionally added \"texture error\" and \"symmetry error\"  to show the reader that these two mostly are not able to depart the Malignant and Benign.\n",
    "\n",
    "\n",
    "6. Note\n",
    "   - The \"worst\" (largest cell) measurements consistently show better class separation than the \"mean\" measurements, confirming "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f5893",
   "metadata": {},
   "source": [
    "### Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count outliers using IQR method\n",
    "outlier_counts = {}\n",
    "for col in feature_cols:\n",
    "    q1, q3 = df[col].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    outlier_counts[col] = ((df[col] < lower) | (df[col] > upper)).sum()\n",
    "\n",
    "# Display features with most outliers\n",
    "outlier_series = pd.Series(outlier_counts).sort_values(ascending=False)\n",
    "print(\"Features with most outliers:\")\n",
    "print(outlier_series.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc958d",
   "metadata": {},
   "source": [
    "Outliers are present in error-related features. In medical data, outliers often represent clinically significant cases and should not be automatically removed. Use robust scaling techniques instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d6eee",
   "metadata": {},
   "source": [
    "## Verify Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292009df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Compute the Metrics\n",
    "features = df.columns.drop([\"target\",\"diagnosis_label\"]) # Assuming 'target' is the label column\n",
    "\n",
    "# a. Missing Values\n",
    "total_missing = df.isna().sum().sum()\n",
    "\n",
    "# b. Duplicates\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "# c. Unnamed Columns (often artifacts from saving CSVs without index=False)\n",
    "unnamed_cols = [c for c in df.columns if \"unnamed\" in c.lower()]\n",
    "\n",
    "# d. Negative Values (Physical measurements like Radius shouldn't be negative)\n",
    "# We check if ANY value in the feature columns is less than 0\n",
    "has_negative_values = (df[features] < 0).any().any()\n",
    "\n",
    "# e. Zero Variance (Columns that have the same value for every single row)\n",
    "variances = df[features].var()\n",
    "zero_variance_cols = variances[variances == 0].index.tolist()\n",
    "\n",
    "# 2. Prepare Data for the Table\n",
    "# We create a list of results with a \"Pass/Fail\" logic\n",
    "quality_report = [\n",
    "    [\"Missing Values\", total_missing, \"Pass\" if total_missing == 0 else \"Fail\"],\n",
    "    [\"Duplicate Rows\", duplicate_rows, \"Pass\" if duplicate_rows == 0 else \"Fail\"],\n",
    "    [\"Unnamed Columns\", len(unnamed_cols), \"Pass\" if len(unnamed_cols) == 0 else \"Fail\"],\n",
    "    [\"Negative Values\", \"Yes\" if has_negative_values else \"No\", \"Pass\" if not has_negative_values else \"Fail\"],\n",
    "    [\"Zero-Variance Features\", len(zero_variance_cols), \"Pass\" if len(zero_variance_cols) == 0 else \"Fail\"]\n",
    "]\n",
    "\n",
    "# Create a DataFrame for the plot\n",
    "report_df = pd.DataFrame(quality_report, columns=[\"Quality Check\", \"Result\", \"Verdict\"])\n",
    "\n",
    "# 3. Plot the Table\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Create the table\n",
    "table = ax.table(cellText=report_df.values, \n",
    "                 colLabels=report_df.columns, \n",
    "                 loc='center', \n",
    "                 cellLoc='center',\n",
    "                 colColours=[\"#f2f2f2\"] * 3) # Grey header background\n",
    "\n",
    "# Style the table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.2, 1.8) # Adjust row height\n",
    "\n",
    "# Color code the 'Verdict' column\n",
    "# (Rows are numbered 1 to 5, Column 2 is 'Verdict')\n",
    "for i in range(len(quality_report)):\n",
    "    cell = table[(i + 1, 2)] \n",
    "    if quality_report[i][2] == \"Pass\":\n",
    "        cell.set_facecolor(\"#d9f7be\") # Green for Pass\n",
    "    else:\n",
    "        cell.set_facecolor(\"#ffccc7\") # Red for Fail\n",
    "\n",
    "plt.title(\"Data Quality Sanity Check\", fontsize=14, y=0.98)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef01ee",
   "metadata": {},
   "source": [
    "Conclusion: The dataset is clean with no missing values, duplicates, or invalid entries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "breast_cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
